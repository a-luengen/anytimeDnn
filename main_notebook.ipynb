{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "***** Stats for densenet121 *****\n",
      "trainabel: 6,994,856\n",
      "total:     6,994,856\n",
      "\n",
      "***** Stats for densenet169 *****\n",
      "trainabel: 12,551,080\n",
      "total:     12,551,080\n",
      "\n",
      "***** Stats for resnet18 *****\n",
      "trainabel: 11,189,352\n",
      "total:     11,189,352\n",
      "\n",
      "***** Stats for resnet101 *****\n",
      "trainabel: 42,574,440\n",
      "total:     42,574,440\n",
      "building network of steps: \n",
      "[4, 4, 4, 4] 16\n",
      " ********************** Block 1  **********************\n",
      "|\t\tinScales 4 outScales 4 inChannels 32 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 4 inChannels 48 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 4 inChannels 64 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 4 inChannels 80 outChannels 16\t\t|\n",
      "\n",
      " ********************** Block 2  **********************\n",
      "|\t\tinScales 4 outScales 3 inChannels 96 outChannels 16\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 112, outChannels 56\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 56 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 72 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 88 outChannels 16\t\t|\n",
      "\n",
      " ********************** Block 3  **********************\n",
      "|\t\tinScales 3 outScales 2 inChannels 104 outChannels 16\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 120, outChannels 60\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 60 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 76 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 92 outChannels 16\t\t|\n",
      "\n",
      " ********************** Block 4  **********************\n",
      "|\t\tinScales 2 outScales 1 inChannels 108 outChannels 16\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 124, outChannels 62\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 62 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 78 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 94 outChannels 16\t\t|\n",
      "\n",
      "\n",
      "***** Stats for msdnet4 *****\n",
      "trainabel: 17,891,392\n",
      "total:     17,891,392\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import getModelWithOptimized\n",
    "\n",
    "def printStats(model):\n",
    "    parameters = sum(p.data.nelement() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'trainabel: {trainable:,d}')\n",
    "    print(f'total:     {parameters:,d}')\n",
    "\n",
    "archs = ['densenet121', 'densenet169', 'resnet18', 'resnet101', 'msdnet4', 'msdnet5', 'msdnet10']\n",
    "\n",
    "for arch in archs:\n",
    "    net = getModelWithOptimized(arch, n=0, batch_size=1)\n",
    "    print(f'\\n***** Stats for {arch} *****')\n",
    "    printStats(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSfGiPcaaMST"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_Rgaj9ouLDl"
   },
   "outputs": [],
   "source": [
    "# copy anytimeDnn data\n",
    "#!cp -r drive/My\\ Drive/reducedAnytimeDnn/* .\n",
    "!mkdir data\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/data/ImagenetDataset.py ./data/ImagenetDataset.py\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/data/__init__.py ./data/__init__.py\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/densenet .\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/msdnet .\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/resnet .\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpLmS3GJbjJw"
   },
   "outputs": [],
   "source": [
    "#!pip install -r drive/My\\ Drive/reducedAnytimeDnn/requirements.txt\n",
    "#!pip3 install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!conda install pytorch==1.5.0 torchvision==0.6.0 cudatoolkit=10.1 -c pytorch\n",
    "!nvidia-smi\n",
    "#!pip install numpy\n",
    "#!pip uninstall torch torchvision\n",
    "#!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCwwGlPKxDBP",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10.2\nFalse\nTrue\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3gbzNz5ZeiD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from msdnet.dataloader import get_dataloaders_alt\n",
    "from resnet import ResNet\n",
    "import densenet.densenet as dn\n",
    "\n",
    "from data.ImagenetDataset import get_zipped_dataloaders\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "from utils import *\n",
    "\n",
    "################################- Constants for Checkpoints -###################################\n",
    "# File name containing checkpoint for given architecture: <arch_name>_<EPOCH>_checkpoint.pth.tar\n",
    "LAST_CHECKPOINT_EPOCH = 0\n",
    "# True: Resume from a checkpoint file stored in the checkpoint subdirectory \n",
    "# or use default if none is found\n",
    "# False: Do not resume from any possible checkpoint file\n",
    "RESUME = True\n",
    "ARCH = 'resnet50'\n",
    "ARCH_NAMES = ['resnet50', 'resnet101', 'resnet152', 'densenet121', 'densenet169']\n",
    "################################################################################################\n",
    "\n",
    "IS_DEBUG = True\n",
    "DEBUG_ITERATIONS = 40\n",
    "STAT_FREQUENCY = 10#200\n",
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GPU_ID = None\n",
    "START_EPOCH = 0\n",
    "EPOCHS = 90\n",
    "CHECKPOINT_INTERVALL = 2 \n",
    "\n",
    "\n",
    "#CHECKPOINT_DIR = 'drive/My Drive/reducedAnytimeDnn/checkpoints'\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "# for repo:\n",
    "# raw images\n",
    "# DATA_PATH = \"data/imagenet_images\"\n",
    "# zipped preprocessed images\n",
    "DATA_PATH = \"data/imagenet_full\"\n",
    "# for colab:\n",
    "# DATA_PATH = \"drive/My Drive/reducedAnytimeDnn/data/imagenet_images\"\n",
    "BATCH_SIZE = 5#16\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "def main(argv):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    n_gpus_per_node = torch.cuda.device_count()\n",
    "    logging.info(f\"Found {n_gpus_per_node} GPU(-s)\")\n",
    "\n",
    "    # create model \n",
    "    model = getModel(ARCH)\n",
    "\n",
    "    logging.info(f\"Training Arch:{ARCH}\")\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "      logging.warning(\"Using CPU for slow training process\")\n",
    "    else:\n",
    "      logging.debug(\"Cuda is available\")\n",
    "      if GPU_ID is not None:\n",
    "        logging.info(f\"Using specific GPU: {GPU_ID}\")\n",
    "        logging.warning(\"This will reduce the training speed significantly.\")\n",
    "        torch.cuda.set_device(GPU_ID)\n",
    "        model.cuda(GPU_ID)\n",
    "      else:\n",
    "        logging.info(\"Using all available GPUs\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            logging.info(f\"gpu:{i} - {torch.cuda.get_device_name(i)}\")\n",
    "        model = nn.DataParallel(model).cuda()\n",
    "    \n",
    "    # loss function (criterion) and optimizer\n",
    "    if torch.cuda.is_available():\n",
    "      logging.info(\"Move cross entropy to device\")\n",
    "      criterion = nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "      criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), \n",
    "        LEARNING_RATE, \n",
    "        momentum=MOMENTUM, \n",
    "        weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    train_loader, test_loader, _ = get_zipped_dataloaders(\n",
    "        os.path.join(os.getcwd(), \"data\", \"imagenet_full\"), \n",
    "        BATCH_SIZE, \n",
    "        use_valid=True)\n",
    "\n",
    "\n",
    "    # size of batch:\n",
    "    logging.debug(get_batch_size_stats(train_loader))\n",
    "    \n",
    "    if RESUME:\n",
    "        model, optimizer, start_epoch, best_acc  = resumeFromPath(\n",
    "            os.path.join(\n",
    "                os.getcwd(), \n",
    "                CHECKPOINT_DIR, \n",
    "                f\"{ARCH}_{LAST_CHECKPOINT_EPOCH}{CHECKPOINT_POSTFIX}\"), \n",
    "            model, \n",
    "            optimizer)\n",
    "    else:\n",
    "        start_epoch = START_EPOCH\n",
    "        best_acc = 0.0\n",
    "    \n",
    "    checkpoint_time = AverageMeter('Checkpoint Time', ':6.3f')\n",
    "    epoch_time = AverageMeter('Epoch Time', ':6.3f')\n",
    "    # train loop\n",
    "    end = time.time()\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        \n",
    "        # train for one epoch\n",
    "        logging.debug('Running train loop')\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        \n",
    "        #evaluate the network on test set\n",
    "        logging.debug('Compute accuracy')\n",
    "        acc = validate(test_loader, model, criterion)\n",
    "        \n",
    "        # remember top acc\n",
    "        is_best = acc > best_acc\n",
    "        best_acc = max(acc, best_acc)\n",
    "        \n",
    "        # safe model\n",
    "        if epoch % CHECKPOINT_INTERVALL == 0 or is_best or IS_DEBUG:\n",
    "            start = time.time()\n",
    "            save_checkpoint(\n",
    "                getStateDict(\n",
    "                    model, \n",
    "                    epoch, \n",
    "                    ARCH, \n",
    "                    best_acc, \n",
    "                    optimizer), \n",
    "                is_best, ARCH, os.path.join(os.getcwd(), CHECKPOINT_DIR))\n",
    "            checkpoint_time.update(time.time() - start)\n",
    "            logging.info(checkpoint_time)\n",
    "        if IS_DEBUG:\n",
    "            break\n",
    "        epoch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        logging.info(epoch)\n",
    "        logging.info(f\"Avg-Epoch={epoch_time.avg}sec, Avg-Checkp.={checkpoint_time.avg}sec\")\n",
    "    logging.info(f\"Best accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[[0.5707, 0.5681, 0.3645, 0.0510],\n          [0.7279, 0.7553, 0.3766, 0.5981],\n          [0.5244, 0.7212, 0.0399, 0.0585],\n          [0.6373, 0.6730, 0.6344, 0.7679]],\n\n         [[0.3602, 0.6710, 0.0085, 0.3773],\n          [0.8418, 0.4608, 0.4441, 0.4968],\n          [0.3460, 0.4951, 0.9141, 0.2032],\n          [0.8242, 0.4571, 0.5274, 0.7714]]],\n\n\n        [[[0.3617, 0.7562, 0.2090, 0.8389],\n          [0.4368, 0.1903, 0.1011, 0.4792],\n          [0.2043, 0.7668, 0.7142, 0.7845],\n          [0.1320, 0.9561, 0.7371, 0.8890]],\n\n         [[0.6037, 0.3062, 0.7786, 0.3867],\n          [0.0067, 0.7528, 0.5455, 0.9434],\n          [0.9406, 0.3588, 0.2097, 0.3950],\n          [0.0163, 0.8539, 0.6199, 0.0292]]],\n\n\n        [[[0.3770, 0.5892, 0.3547, 0.1008],\n          [0.9942, 0.8421, 0.7856, 0.7889],\n          [0.2210, 0.7621, 0.1160, 0.7656],\n          [0.5356, 0.6063, 0.4188, 0.0334]],\n\n         [[0.5156, 0.3893, 0.5888, 0.4524],\n          [0.8912, 0.3957, 0.3425, 0.2525],\n          [0.9201, 0.8308, 0.2829, 0.3284],\n          [0.9911, 0.1833, 0.6977, 0.3607]]]])\n\ntensor([[[[0.5707, 0.5681, 0.3645, 0.0510],\n          [0.7279, 0.7553, 0.3766, 0.5981],\n          [0.5244, 0.7212, 0.0399, 0.0585],\n          [0.6373, 0.6730, 0.6344, 0.7679]],\n\n         [[0.3602, 0.6710, 0.0085, 0.3773],\n          [0.8418, 0.4608, 0.4441, 0.4968],\n          [0.3460, 0.4951, 0.9141, 0.2032],\n          [0.8242, 0.4571, 0.5274, 0.7714]]],\n\n\n        [[[0.3617, 0.7562, 0.2090, 0.8389],\n          [0.4368, 0.1903, 0.1011, 0.4792],\n          [0.2043, 0.7668, 0.7142, 0.7845],\n          [0.1320, 0.9561, 0.7371, 0.8890]],\n\n         [[0.6037, 0.3062, 0.7786, 0.3867],\n          [0.0067, 0.7528, 0.5455, 0.9434],\n          [0.9406, 0.3588, 0.2097, 0.3950],\n          [0.0163, 0.8539, 0.6199, 0.0292]]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor = torch.rand(3, 2, 4, 4)\n",
    "print(tensor)\n",
    "print()\n",
    "print(tensor[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rnyS9VgZeiN"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes accuracy over the k top predictions for the values of k\"\"\"\n",
    "    \n",
    "    # reduce memory consumption on following calculations\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        \n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"\n",
    "        Sets learning rate to default value, decayed by division with 10 every 25 epochs and \n",
    "        updates the lr in the optimizer.\n",
    "    \"\"\"\n",
    "    if not epoch % 25 == 0 and epoch > 0:\n",
    "        return\n",
    "    lr = LEARNING_RATE * (0.1 ** (epoch // 25)) \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    batch_time = AverageMeter('Batch Time', ':6.3f')\n",
    "    data_load_time = AverageMeter('Data Time', ':6.3f')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (img, target) in enumerate(train_loader):\n",
    "        \n",
    "        if GPU_ID is not None:\n",
    "            img = img.cuda(GPU_ID, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU_ID, non_blocking=True)\n",
    "        # time it takes to load data\n",
    "        data_load_time.update(time.time() - end)\n",
    "        \n",
    "        # compute output of the current network\n",
    "        output = model(img)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        \n",
    "        top1.update(acc1[0], img.size(0))\n",
    "        top5.update(acc5[0], img.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # printing statistics every 2000 mini batch size\n",
    "        if i % STAT_FREQUENCY == STAT_FREQUENCY - 1:            \n",
    "            logging.info(f'Epoch {epoch} Train loop - Iteration {i}/{len(train_loader)} - Loss {loss}')\n",
    "            logging.info(top1)\n",
    "            logging.info(top5)\n",
    "            logging.info(batch_time)\n",
    "            logging.info(data_load_time)\n",
    "        if IS_DEBUG and i == DEBUG_ITERATIONS:\n",
    "                break\n",
    "    logging.info(f\"Epoch {epoch} train summary: Avg. Acc@1={top1.avg:6.2f} - \" \n",
    "        + f\"Avg. Acc@5={top5.avg:6.2f} - \" \n",
    "        + f\"Avg. Batch={batch_time.avg:6.2f}sec - \"\n",
    "        + f\"Avg. DataLoad={data_load_time.avg}sec\" )\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"Compute average accuracy, top 1 and top 5 accuracy\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    batch_time = AverageMeter('Batch Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i , (img, target) in enumerate(val_loader):\n",
    "            # check if could be moved to cuda device\n",
    "            if GPU_ID is not None:\n",
    "                img = img.cuda(GPU_ID, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU_ID, non_blocking=True)\n",
    "                \n",
    "            # compute output\n",
    "            output = model(img)\n",
    "            \n",
    "            # compute loss\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(),img.size(0))\n",
    "            top1.update(prec1.item(), img.size(0))\n",
    "            top5.update(prec5.item(), img.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "            if i % STAT_FREQUENCY == STAT_FREQUENCY - 1:\n",
    "                logging.info(f'validation loop {i} of {len(val_loader)}')\n",
    "                logging.info(losses)\n",
    "                logging.info(top1)\n",
    "                logging.info(top5)\n",
    "                logging.info(batch_time)\n",
    "            if IS_DEBUG and i == DEBUG_ITERATIONS:\n",
    "                return top1.avg\n",
    "    return top1.avg\n",
    "\n",
    "def loadAndEvaluate():\n",
    "    model = getModel(ARCH)\n",
    "\n",
    "    if os.path.exists(os.path.join(CHECKPOINT_DIR, ARCH + '_model_best.pth.tar')):\n",
    "        logging.debug(\"Loading best model\")\n",
    "        load_path = os.path.join(CHECKPOINT_DIR, ARCH + '_model_best.pth.tar')\n",
    "    else:\n",
    "        logging.debug(\"Loading default model\")\n",
    "        load_path = os.path.join(CHECKPOINT_DIR, ARCH + '_checkpoint.pth.tar')\n",
    "    \n",
    "    logging.debug('Loading: ' + load_path)\n",
    "\n",
    "    model, _, _ = resumeFromPath(load_path, model)\n",
    "\n",
    "    logging.debug('Loading Test Data..')\n",
    "\n",
    "    _, _, testLoader = get_zipped_dataloaders(DATA_PATH, BATCH_SIZE, use_valid=True)\n",
    "    grndT, pred = evaluateModel(model, testLoader)\n",
    "\n",
    "    printStats(grndT, pred)\n",
    "\n",
    "def evaluateModel(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logging.debug(f'Loaded testData with {len(loader.dataset)} testImages and {BATCH_SIZE} images per batch.')\n",
    "\n",
    "        classes = getClasses(os.path.join(DATA_PATH, 'val'))\n",
    "        grndT, pred = [], []\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            logging.debug(f\"Evaluating: {i}-th iteration\")\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            pred = pred + [classes[predicted[k]] for k in range(BATCH_SIZE)]\n",
    "            grndT = grndT + [classes[labels[j]] for j in range(BATCH_SIZE)]\n",
    "            \n",
    "            if IS_DEBUG and i == DEBUG_ITERATIONS:\n",
    "                break\n",
    "        return grndT, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7NxTVWQSuiL",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:root:Found 0 GPU(-s)\nINFO:root:Loading model: resnet50\nINFO:root:Training Arch:resnet50\nWARNING:root:Using CPU for slow training process\n/home/alex/Projects/Studium/anytimeDnn/data/imagenet_full/index-train.txt\n/home/alex/Projects/Studium/anytimeDnn/data/imagenet_full/index-val.txt\nDEBUG:root:Input:\n752640 Elements times 4 bytes is 3010560\nTarget:\n5 Elements times 8 bytes is 40\nINFO:root:=&gt; no checkpoint found at &#39;/home/alex/Projects/Studium/anytimeDnn/checkpoints/resnet50_0_checkpoint.pth.tar&#39;\nDEBUG:root:Running train loop\nNo file found /home/alex/Projects/Studium/anytimeDnn/checkpoints/resnet50_0_checkpoint.pth.tar\nINFO:root:Epoch 0 Train loop - Iteration 9/6379 - Loss 18.753629684448242\nINFO:root:Acc@1   0.00 (  4.00) (  0.00) ( 20.00)\nINFO:root:Acc@5   0.00 ( 14.00) (  0.00) ( 40.00)\nINFO:root:Batch Time 14.378 (15.921) (13.981) (18.125)\nINFO:root:Data Time  0.002 ( 0.006) ( 0.001) ( 0.042)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-4-2bb7ad5419e9&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----&gt; 9\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m&lt;ipython-input-2-d040e4c58bf1&gt;\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m&#39;Running train loop&#39;\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 127\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m#evaluate the network on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m&lt;ipython-input-3-53d3e4d52acc&gt;\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/capp/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         &quot;&quot;&quot;\n\u001b[0;32m--&gt; 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/capp/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---&gt; 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "\n",
    "curTime = datetime.datetime.now()\n",
    "\n",
    "log_level = logging.DEBUG\n",
    "\n",
    "logging.basicConfig(level=log_level)\n",
    "try:\n",
    "  main(sys.argv)\n",
    "except Exception as e:\n",
    "  torch.cuda.empty_cache()\n",
    "  print(\"Oh no! Bad things happened...\")\n",
    "  print(e)\n",
    "  traceback.print_exc()\n",
    "finally:\n",
    "  torch.cuda.empty_cache()\n",
    "#logging.info(f\"Top1 Accuracy: {loadAndEvaluate()}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main_notebook.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('capp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "eb9f6afae542b8db896e4dcf3a851d3ffe665752691e690e4032ea643745791b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}