{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('capp': conda)",
   "display_name": "Python 3.8.5 64-bit ('capp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "eb9f6afae542b8db896e4dcf3a851d3ffe665752691e690e4032ea643745791b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import *\n",
    "from data.ImagenetDataset import get_zipped_dataloaders, REDUCED_SET_PATH\n",
    "from train import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_PATH = 'runs/'\n",
    "DATA_PATH = REDUCED_SET_PATH\n",
    "IS_DEBUG = True\n",
    "DEBUG_ITERATIONS = 40\n",
    "STAT_FREQUENCY = 200\n",
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GPU_ID = None\n",
    "START_EPOCH = 0\n",
    "EPOCHS = 2\n",
    "CHECKPOINT_INTERVALL = 4 \n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "LOG_FLOAT_PRECISION = ':6.4f'\n",
    "\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGUEMTNS FOR THE MSD-Net Configurtaion and Training\n",
    "class Object(object):\n",
    "  pass\n",
    "\n",
    "args = None\n",
    "\n",
    "try: \n",
    "  args = arg_parser.parse_args()\n",
    "except:\n",
    "  args = Object()\n",
    "  args_dict = {\n",
    "      'gpu': 'gpu:0',\n",
    "      'use_valid': True,\n",
    "      'data': 'ImageNet',\n",
    "      'save': os.path.join(os.getcwd(), 'save'),\n",
    "      'evalmode': None,\n",
    "      'start_epoch': START_EPOCH,\n",
    "      'epochs': EPOCHS,\n",
    "      'arch': 'msdnet',\n",
    "      'seed': 42,\n",
    "      'test_interval': 10,\n",
    "\n",
    "      'grFactor': \"1-2-4-4\",\n",
    "      'bnFactor': \"1-2-4-4\",\n",
    "      'nBlocks': 3,\n",
    "      'reduction': 0.5,\n",
    "      'bottleneck': True,\n",
    "      'prune': 'max',\n",
    "      'growthRate': 16,\n",
    "      'base': 4,\n",
    "      'step': 4,\n",
    "      'stepmode': 'even',\n",
    "      \n",
    "      'lr': LEARNING_RATE,\n",
    "      'lr_type': 'multistep',\n",
    "      'momentum': MOMENTUM,\n",
    "      'weight_decay': WEIGHT_DECAY,\n",
    "      'resume': False,\n",
    "      'data_root': DATA_PATH,\n",
    "      'batch_size': BATCH_SIZE,\n",
    "      'workers': 1,\n",
    "      'print_freq': STAT_FREQUENCY\n",
    "  } \n",
    "\n",
    "  for key in args_dict:\n",
    "    setattr(args, key, args_dict[key])\n",
    "    #print(getattr(args, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join(RUN_PATH, 'experiment_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # MAIN LOOP\n",
    "    model = get_msd_net_model()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                    args.lr,\n",
    "                                    momentum=args.momentum,\n",
    "                                    weight_decay=args.weight_decay)\n",
    "\n",
    "    calc_lr = lambda epoch: epoch // 30\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=calc_lr)\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_zipped_dataloaders(args.data_root, args.batch_size, use_valid=True)\n",
    "\n",
    "    best_prec1, best_epoch = 0.0, 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # train()\n",
    "        train_loss, train_prec1, train_prec5, lr = train(train_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "        # validate()\n",
    "        val_loss, val_prec1, val_prec5 = validate(val_loader, model, criterion)\n",
    "        scheduler.step()\n",
    "\n",
    "        is_best = val_prec1 > best_prec1\n",
    "        if is_best:\n",
    "            best_prec1 = va_prec1\n",
    "            best_epoch = epoch\n",
    "            logging.info(f'Best var_prec1 {best_prec1}')\n",
    "        \n",
    "        if is_best or epoch % CHECKPOINT_INTERVALL == 0:\n",
    "            save_checkpoint(getStateDict(model, epoch, 'msdnet', best_acc, optimizer),\n",
    "                            is_best, \n",
    "                            'msdnet', \n",
    "                            CHECKPOINT_DIR)\n",
    "        if epoch % args.test_interval == 0:\n",
    "            avg_loss, avg_top1, avg_top5 =validate(test_loader, model, criterion)\n",
    "            writer.add_scalar('test_loss', \n",
    "                    avg_loss / args.test_interval,\n",
    "                    epoch + 1)\n",
    "            writer.add_scalar('test_top1', avg_top1, epoch + 1)\n",
    "            writer.add_scalar('test_top5', avg_top5, epoch + 1)\n",
    "\n",
    "\n",
    "    logging.info(f'Best val_prec1: {best_prec1:.4f} at epoch {best_epoch}')\n",
    "\n",
    "    logging.info('*************** Final prediction results ***************')\n",
    "    validate(test_loader, model, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion)-> float, float, float:\n",
    "    batch_time = AverageMeter('Batch Time', LOG_FLOAT_PRECISION)\n",
    "    losses = AverageMeter('Loss', LOG_FLOAT_PRECISION)\n",
    "    data_time = AverageMeter('Data Time', LOG_FLOAT_PRECISION)\n",
    "    top1, top5 = [], []\n",
    "    for i in range(args.nBlocks):\n",
    "        top1.append(AverageMeter(f'Top1-{i+1}', LOG_FLOAT_PRECISION))\n",
    "        top5.append(AverageMeter(f'Top1-{i+1}', LOG_FLOAT_PRECISION))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (img, target) in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda(non_blocking=True)\n",
    "                target = target.cuda(non_blocking=True)\n",
    "            \n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            output = model(img)\n",
    "            if not isinstance(output, list):\n",
    "                output = [output]\n",
    "\n",
    "            loss = 0.0\n",
    "            for j in range(len(output)):\n",
    "                loss += criterion(output[j], target)\n",
    "\n",
    "            losses.update(loss.item(), img.size(0))\n",
    "\n",
    "            for j in range(len(output)):\n",
    "                prec1, prec5 = accuracy(output[j].data, topk=(1,5))\n",
    "                top1[j].update(prec1.item(), img.size(0))\n",
    "                top5[j].update(prec5.item(), img.size(0))\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            \n",
    "            if i % args.print_freq == 0:\n",
    "                logging.info(f'Epoch: [{i+1}/{len(val_loader)}]\\t'\n",
    "                      f'Time {batch_time.avg:.3f}\\t'\n",
    "                      f'Data {data_time.avg:.3f}\\t'\n",
    "                      f'Loss {losses.val:.4f}\\t'\n",
    "                      f'Acc@1 {top1[-1].val:.4f}\\t'\n",
    "                      f'Acc@5 {top5[-1].val:.4f}')\n",
    "            end = time.time()\n",
    "    \n",
    "    for j in range(args.nBlocks):\n",
    "        logging.info(f' * prec@1 {top1[j].avg:.3f} prec@5 {top5[j].avg:.3f}')\n",
    "        logging.info(f' * prec@1 {top1[-1].avg:.3f} prec@5 {top5[-1].avg:.3f}')\n",
    "    \n",
    "    return losses.avg, top1[-1].avg, top5[-1].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "    batch_time = AverageMeter('Batch Time', LOG_FLOAT_PRECISION)\n",
    "    data_time = AverageMeter('Data Time', LOG_FLOAT_PRECISION)\n",
    "    losses = AverageMeter('Loss', LOG_FLOAT_PRECISION)\n",
    "    top1, top5 = [],[]\n",
    "\n",
    "    for i in range(args.nBlocks):\n",
    "        top1.append(AverageMeter(f'Top1-{i+1}', LOG_FLOAT_PRECISION))\n",
    "        top5.append(AverageMeter(f'Top5-{i+1}', LOG_FLOAT_PRECISION))\n",
    "    \n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    running_lr = scheduler.get_last_lr()\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        image, target = data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "                # time it takes to load data\n",
    "\n",
    "        output = model(image)\n",
    "        if not isinstance(output, list):\n",
    "            output = [output]\n",
    "\n",
    "        loss = 0.0\n",
    "        for j in range(len(output)):\n",
    "            loss += criterion(output[j], target)\n",
    "        \n",
    "        losses.update(loss.item(), image.size(0))\n",
    "\n",
    "        for j in range(len(output)):\n",
    "            prec1, prec5 = accuracy(output[j].data, target, topk=(1, 5))\n",
    "            top1[j].update(prec1.item(), image.size(0))\n",
    "            top5[j].update(prec5.item(), image.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            writer.add_scalar('training_loss', \n",
    "                                loss / args.print_freq,\n",
    "                                epoch * len(train_loader) + 1)\n",
    "            logging.info(\n",
    "                f'Epoch: [{epoch}][{i + 1}/{len(train_loader)}]\\t'\n",
    "                f'Time {batch_time.avg:.3f}\\t'\n",
    "                f'Data {data_time.avg:.3f}\\t'\n",
    "                f'Loss {losses.val:.4f}\\t'\n",
    "                f'Acc@1 {top1[-1].val:.4f}\\t'\n",
    "                f'Acc@5 {top5[-1].val:.4f}')\n",
    "    \n",
    "    return losses.avg, top1[-1].avg, top5[-1].avg, running_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "building network of steps: \n[4] 4\n ********************** Block 1  **********************\n|\t\tinScales 4 outScales 4 inChannels 224 outChannels 16\t\t|\n\n|\t\tinScales 4 outScales 3 inChannels 240 outChannels 16\t\t|\n|\t\tTransition layer inserted! (max), inChannels 256, outChannels 128\t|\n\n|\t\tinScales 3 outScales 2 inChannels 128 outChannels 16\t\t|\n|\t\tTransition layer inserted! (max), inChannels 144, outChannels 72\t|\n\n|\t\tinScales 2 outScales 1 inChannels 72 outChannels 16\t\t|\n|\t\tTransition layer inserted! (max), inChannels 88, outChannels 44\t|\n\ndata/imagenet_red/index-train.txt\ndata/imagenet_red/index-val.txt\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b3f47c9a9b7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-67d49ed2ba6d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_prec5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# validate()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_prec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_prec5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-8a620f40a86a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/capp/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/capp/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}