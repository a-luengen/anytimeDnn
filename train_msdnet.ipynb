{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('capp': conda)",
   "display_name": "Python 3.8.5 64-bit ('capp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "eb9f6afae542b8db896e4dcf3a851d3ffe665752691e690e4032ea643745791b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy anytimeDnn data\n",
    "#!cp -r drive/My\\ Drive/reducedAnytimeDnn/* .\n",
    "!mkdir data\n",
    "!mkdir data/imagenet_red\n",
    "!mkdir data/imagenet_full\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/data/utils.py ./data/utils.py \n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/data/ImagenetDataset.py ./data/ImagenetDataset.py\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/data/__init__.py ./data/__init__.py\n",
    "!cp drive/My\\ Drive/reducedAnytimeDnn/data/imagenet_red/index-* ./data/imagenet_red\n",
    "#!cp drive/My\\ Drive/reducedAnytimeDnn/data/imagenet_full/index-* ./data/imagenet_full\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/densenet .\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/msdnet .\n",
    "!cp -r drive/My\\ Drive/reducedAnytimeDnn/resnet .\n",
    "!cp drive/My\\ Drive/reducedAnytimeDnn/utils.py ./utils.py\n",
    "!cp drive/My\\ Drive/reducedAnytimeDnn/train.py ./train.py\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r drive/My\\ Drive/reducedAnytimeDnn/requirements.txt\n",
    "#!pip3 install torch===1.6.0 torchvision===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!conda install pytorch==1.5.0 torchvision==0.6.0 cudatoolkit=10.1 -c pytorch\n",
    "!nvidia-smi\n",
    "#!pip install numpy\n",
    "#!pip uninstall torch torchvision\n",
    "#!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
    "!pip install dareblopy==0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import msdnet.models\n",
    "\n",
    "from utils import *\n",
    "from data.ImagenetDataset import get_zipped_dataloaders, REDUCED_SET_PATH, FULL_SET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_PATH = 'runs/'\n",
    "DATA_PATH = REDUCED_SET_PATH\n",
    "IS_DEBUG = True\n",
    "DEBUG_ITERATIONS = 3\n",
    "STAT_FREQUENCY = 200\n",
    "LEARNING_RATE = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GPU_ID = None\n",
    "START_EPOCH = 0\n",
    "EPOCHS = 2\n",
    "CHECKPOINT_INTERVALL = 4 \n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "\n",
    "LOG_FLOAT_PRECISION = ':6.4f'\n",
    "\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARGUEMTNS FOR THE MSD-Net Configurtaion and Training\n",
    "class Object(object):\n",
    "  pass\n",
    "\n",
    "args = None\n",
    "\n",
    "try: \n",
    "  args = arg_parser.parse_args()\n",
    "except:\n",
    "  args = Object()\n",
    "\n",
    "  growFactor = list(map(int, \"1-2-4-4\".split(\"-\")))\n",
    "  bnFactor = list(map(int, \"1-2-4-4\".split(\"-\")))\n",
    "\n",
    "  args_dict = {\n",
    "      'gpu': 'gpu:0',\n",
    "      'use_valid': True,\n",
    "      'data': 'ImageNet',\n",
    "      'save': os.path.join(os.getcwd(), 'save'),\n",
    "      'evalmode': None,\n",
    "      'start_epoch': START_EPOCH,\n",
    "      'epochs': EPOCHS,\n",
    "      'arch': 'msdnet',\n",
    "      'seed': 42,\n",
    "      'test_interval': 10,\n",
    "\n",
    "      'grFactor': growFactor,\n",
    "      'bnFactor': bnFactor,\n",
    "      'nBlocks': 5,\n",
    "      'nChannels': 32,\n",
    "      'nScales': len(growFactor),\n",
    "      'reduction': 0.5,\n",
    "      'bottleneck': True,\n",
    "      'prune': 'max',\n",
    "      'growthRate': 16,\n",
    "      'base': 4,\n",
    "      'step': 4,\n",
    "      'stepmode': 'even',\n",
    "      \n",
    "      'lr': LEARNING_RATE,\n",
    "      'lr_type': 'multistep',\n",
    "      'momentum': MOMENTUM,\n",
    "      'weight_decay': WEIGHT_DECAY,\n",
    "      'resume': False,\n",
    "      'data_root': DATA_PATH,\n",
    "      'batch_size': BATCH_SIZE,\n",
    "      'workers': 1,\n",
    "      'print_freq': STAT_FREQUENCY\n",
    "  } \n",
    "\n",
    "  for key in args_dict:\n",
    "    setattr(args, key, args_dict[key])\n",
    "    #print(getattr(args, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join(RUN_PATH, 'experiment_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    n_gpus_per_node = torch.cuda.device_count()\n",
    "    logging.info(f\"Found {n_gpus_per_node} GPU(-s)\")\n",
    "\n",
    "\n",
    "    # MAIN LOOP\n",
    "    #model = get_msd_net_model()\n",
    "    model = msdnet.models.msdnet(args)\n",
    "\n",
    "    writer.add_graph(model, torch.rand(1, 3, 224, 224))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        logging.debug(\"Cuda is available.\")\n",
    "        logging.info(\"Using all available GPUs\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            logging.info(f\"gpu:{i} - {torch.cuda.get_device_name(i)}\")\n",
    "        model = nn.DataParallel(model).cuda()\n",
    "        logging.info(\"Moving criterion to device.\")\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    else:\n",
    "        logging.info(\"Using slow CPU training.\")\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                    args.lr,\n",
    "                                    momentum=args.momentum,\n",
    "                                    weight_decay=args.weight_decay)\n",
    "\n",
    "    calc_lr = lambda epoch: epoch // 30\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=calc_lr)\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_zipped_dataloaders(args.data_root, args.batch_size, use_valid=True)\n",
    "\n",
    "    best_prec1, best_epoch = 0.0, 0\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        logging.info(f\"Started Epoch{epoch + 1}/{EPOCHS}\")\n",
    "        # train()\n",
    "        train_loss, train_prec1, train_prec5, lr = train(train_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "        # validate()\n",
    "        val_loss, val_prec1, val_prec5 = validate(val_loader, model, criterion)\n",
    "        scheduler.step()\n",
    "\n",
    "        is_best = val_prec1 > best_prec1\n",
    "        if is_best:\n",
    "            best_prec1 = val_prec1\n",
    "            best_epoch = epoch\n",
    "            logging.info(f'Best val_prec1 {best_prec1}')\n",
    "        \n",
    "        if is_best or epoch % CHECKPOINT_INTERVALL == 0:\n",
    "            save_checkpoint(getStateDict(model, epoch, 'msdnet', best_prec1, optimizer),\n",
    "                            is_best, \n",
    "                            'msdnet', \n",
    "                            CHECKPOINT_DIR)\n",
    "\n",
    "        if epoch % args.test_interval == 0:\n",
    "            avg_loss, avg_top1, avg_top5 = validate(test_loader, model, criterion)\n",
    "            writer.add_scalar('test_loss', avg_loss, epoch + 1)\n",
    "            writer.add_scalar('test_top1', avg_top1, epoch + 1)\n",
    "            writer.add_scalar('test_top5', avg_top5, epoch + 1)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    logging.info(f'Best val_prec1: {best_prec1:.4f} at epoch {best_epoch}')\n",
    "\n",
    "    logging.info('*************** Final prediction results ***************')\n",
    "    validate(test_loader, model, criterion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Batch Time', LOG_FLOAT_PRECISION)\n",
    "    losses = AverageMeter('Loss', LOG_FLOAT_PRECISION)\n",
    "    data_time = AverageMeter('Data Time', LOG_FLOAT_PRECISION)\n",
    "    top1, top5 = [], []\n",
    "    for i in range(args.nBlocks):\n",
    "        top1.append(AverageMeter(f'Top1-{i+1}', LOG_FLOAT_PRECISION))\n",
    "        top5.append(AverageMeter(f'Top1-{i+1}', LOG_FLOAT_PRECISION))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (img, target) in enumerate(val_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda(non_blocking=True)\n",
    "                target = target.cuda(non_blocking=True)\n",
    "            \n",
    "            data_time.update(time.time() - end)\n",
    "\n",
    "            output = model(img)\n",
    "            if not isinstance(output, list):\n",
    "                output = [output]\n",
    "\n",
    "            loss = 0.0\n",
    "            for j in range(len(output)):\n",
    "                loss += criterion(output[j], target)\n",
    "\n",
    "            losses.update(loss.item(), img.size(0))\n",
    "\n",
    "            for j in range(len(output)):\n",
    "                prec1, prec5 = accuracy(output[j].data, target, topk=(1,5))\n",
    "                top1[j].update(prec1.item(), img.size(0))\n",
    "                top5[j].update(prec5.item(), img.size(0))\n",
    "\n",
    "            batch_time.update(time.time() - end)\n",
    "            \n",
    "            if i % args.print_freq == 0:\n",
    "                logging.info(f'Val - Epoch: [{i+1}/{len(val_loader)}]\\t'\n",
    "                      f'Time {batch_time.avg:.3f}\\t'\n",
    "                      f'Data {data_time.avg:.3f}\\t'\n",
    "                      f'Loss {losses.val:.4f}\\t'\n",
    "                      f'Acc@1 {top1[-1].val:.4f}\\t'\n",
    "                      f'Acc@5 {top5[-1].val:.4f}')\n",
    "            end = time.time()\n",
    "            \n",
    "            if IS_DEBUG and i == DEBUG_ITERATIONS:\n",
    "                return losses.avg, top1[-1].avg, top5[-1].avg\n",
    "\n",
    "    for j in range(args.nBlocks):\n",
    "        logging.info(f' * prec@1 {top1[j].avg:.3f} prec@5 {top5[j].avg:.3f}')\n",
    "    logging.info(f' * prec@1 {top1[-1].avg:.3f} prec@5 {top5[-1].avg:.3f}')\n",
    "    \n",
    "    return losses.avg, top1[-1].avg, top5[-1].avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "    batch_time = AverageMeter('Batch Time', LOG_FLOAT_PRECISION)\n",
    "    data_time = AverageMeter('Data Time', LOG_FLOAT_PRECISION)\n",
    "    losses = AverageMeter('Loss', LOG_FLOAT_PRECISION)\n",
    "    top1, top5 = [],[]\n",
    "\n",
    "    for i in range(args.nBlocks):\n",
    "        top1.append(AverageMeter(f'Top1-{i+1}', LOG_FLOAT_PRECISION))\n",
    "        top5.append(AverageMeter(f'Top5-{i+1}', LOG_FLOAT_PRECISION))\n",
    "    \n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    running_lr = scheduler.get_last_lr()\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        image, target = data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "                # time it takes to load data\n",
    "\n",
    "        output = model(image)\n",
    "        if not isinstance(output, list):\n",
    "            output = [output]\n",
    "\n",
    "        loss = 0.0\n",
    "        for j in range(len(output)):\n",
    "            loss += criterion(output[j], target)\n",
    "        \n",
    "        losses.update(loss.item(), image.size(0))\n",
    "\n",
    "        for j in range(len(output)):\n",
    "            prec1, prec5 = accuracy(output[j].data, target, topk=(1, 5))\n",
    "            top1[j].update(prec1.item(), image.size(0))\n",
    "            top5[j].update(prec5.item(), image.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            writer.add_scalar('training_loss', \n",
    "                                losses.val / len(output) / args.print_freq,\n",
    "                                epoch * len(train_loader) + 1)\n",
    "            logging.info(\n",
    "                f'Train - Epoch: [{epoch}][{i + 1}/{len(train_loader)}]\\t'\n",
    "                f'Time {batch_time.avg:.3f}\\t'\n",
    "                f'Data {data_time.avg:.3f}\\t'\n",
    "                f'Loss {losses.val:.4f}\\t'\n",
    "                f'Acc@1 {top1[-1].val:.4f}\\t'\n",
    "                f'Acc@5 {top5[-1].val:.4f}')\n",
    "\n",
    "        if IS_DEBUG and i == DEBUG_ITERATIONS:\n",
    "            return losses.avg, top1[-1].avg, top5[-1].avg, running_lr\n",
    "\n",
    "    return losses.avg, top1[-1].avg, top5[-1].avg, running_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes accuracy over the k top predictions for the values of k\"\"\"\n",
    "    \n",
    "    # reduce memory consumption on following calculations\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "        \n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir \"{RUN_PATH}\" --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "building network of steps: \n",
      "[4, 4, 4, 4, 4] 20\n",
      " ********************** Block 1  **********************\n",
      "|\t\tinScales 4 outScales 4 inChannels 32 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 4 inChannels 48 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 4 inChannels 64 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 4 inChannels 80 outChannels 16\t\t|\n",
      "\n",
      " ********************** Block 2  **********************\n",
      "|\t\tinScales 4 outScales 4 inChannels 96 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 4 outScales 3 inChannels 112 outChannels 16\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 128, outChannels 64\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 64 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 80 outChannels 16\t\t|\n",
      "\n",
      " ********************** Block 3  **********************\n",
      "|\t\tinScales 3 outScales 3 inChannels 96 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 3 inChannels 112 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 3 outScales 2 inChannels 128 outChannels 16\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 144, outChannels 72\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 72 outChannels 16\t\t|\n",
      "\n",
      " ********************** Block 4  **********************\n",
      "|\t\tinScales 2 outScales 2 inChannels 88 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 104 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 2 inChannels 120 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 2 outScales 1 inChannels 136 outChannels 16\t\t|\n",
      "|\t\tTransition layer inserted! (max), inChannels 152, outChannels 76\t|\n",
      "\n",
      " ********************** Block 5  **********************\n",
      "|\t\tinScales 1 outScales 1 inChannels 76 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 92 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 108 outChannels 16\t\t|\n",
      "\n",
      "|\t\tinScales 1 outScales 1 inChannels 124 outChannels 16\t\t|\n",
      "\n",
      "data/imagenet_red/index-train.txt\n",
      "data/imagenet_red/index-val.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  main(args)\n",
    "except Exception as e:\n",
    "  torch.cuda.empty_cache()\n",
    "  print(\"Oh no! Bad things happened...\")\n",
    "  print(e)\n",
    "  traceback.print_exc()\n",
    "finally:\n",
    "  torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}